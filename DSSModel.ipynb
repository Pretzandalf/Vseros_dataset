{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe0bfb37-3e88-4dcb-867d-ce04f662c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14b8aa9-b7f1-40a3-8446-421b7d9be28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('intfloat/multilingual-e5-large-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a7a6cb-b345-4d50-9c37-28a37692a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('/home/pret/PycharmProjects/Vseros_classification/Datasets/Interaction_table.csv').drop(columns = ['Unnamed: 0'])\n",
    "train_dataset = train_dataset.rename(columns={'watchtime': 'target'})\n",
    "item_features = pd.read_csv('/home/pret/PycharmProjects/Vseros_classification/Datasets/Item_features.csv').drop(columns = ['Unnamed: 0', 'row_number'])\n",
    "test = pd.read_csv('/home/pret/PycharmProjects/Vseros_classification/Datasets/Interaction_table_test.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "#train_dataset = pd.merge(train_dataset, item_features, on='video_id', how='left')\n",
    "#test = pd.merge(test, item_features, on='video_id', how='left')\n",
    "\n",
    "categorical = ['region', 'city', 'category_id', 'author_id', 'long_video']\n",
    "embbedings = ['title', 'description']\n",
    "numeric = [c for c in (item_features.columns.values.tolist() + train_dataset.columns.values.tolist()) if c not in categorical + embbedings +['video_id', 'user_id', 'target']]\n",
    "item_features[embbedings] = item_features[embbedings].fillna('<PAD>')\n",
    "\n",
    "print('Ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dd99fb-691f-4e8a-b04e-946141abed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "if DEBUG:\n",
    "    epochs = 1\n",
    "    max_users = 10\n",
    "else:\n",
    "    epochs = 10\n",
    "    max_users = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e6d8cb-3779-4c44-8481-e79237a497f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_users = (\n",
    "    train_dataset.groupby('user_id')\n",
    "    .agg(\n",
    "        total_interactions=('video_id', 'size'),\n",
    "        positive_interactions=('target', lambda x: (x == 1).sum()),\n",
    "        negative_interactions=('target', lambda x: (x == 0).sum())\n",
    "    )\n",
    "    .query('total_interactions >= 3 and positive_interactions >= 1 and negative_interactions >= 1')\n",
    "    .index\n",
    ")\n",
    "# train_dataset = train_dataset[train_dataset['user_id'].isin(filtered_users)]\n",
    "# train_dataset.reset_index(drop=True, \n",
    "#                inplace=True)\n",
    "\n",
    "random_users = random.sample(list(filtered_users), max_users)\n",
    "X_train, X_val = train_test_split(random_users, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = train_dataset[train_dataset['user_id'].isin(X_train)]\n",
    "val_dataset = train_dataset[train_dataset['user_id'].isin(X_val)]\n",
    "\n",
    "train_dataset.reset_index(drop=True, \n",
    "               inplace=True)\n",
    "\n",
    "val_dataset.reset_index(drop=True, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae38b5cd-4acf-4478-b10a-8c3d967e79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "cat_PAD = {}\n",
    "label_encoder_holder = {}\n",
    "for cat in categorical:\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_dataset[cat] = f'{cat}_' + train_dataset[cat].astype(str)\n",
    "\n",
    "    label_encoder.fit(train_dataset[cat].values.tolist() + [f'{cat}_PAD'])\n",
    "    label_encoder_holder[cat] = label_encoder\n",
    "    cat_PAD[cat] = label_encoder.transform([f'{cat}_PAD']).tolist()[0]\n",
    "    # train_dataset[cat] = label_encoder.transform(train_dataset[[cat]])\n",
    "\n",
    "    # def encode_category(category):\n",
    "    #     if category in label_encoder.classes_:\n",
    "    #         return category\n",
    "    #     else:\n",
    "    #         return f'{cat}_PAD'\n",
    "\n",
    "    # test[cat] = test[cat].apply(encode_category)\n",
    "\n",
    "    # test[cat] = label_encoder.transform(test[[cat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d9a3143e-e2bd-497e-9de9-4eb1333a9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSMDataset(Dataset):\n",
    "    def __init__(self, train_dataset, item_features, users, numeric, categorical, embbedings, label_encoder_holder, sentence_model, trainfor = True, predictfor = False):\n",
    "        self.train_dataset = train_dataset\n",
    "        if predictfor == False: \n",
    "            self.train_dataset = train_dataset[train_dataset['user_id'].isin(users)]\n",
    "            self.train_dataset.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        self.item_features =item_features\n",
    "        self.users = users\n",
    "        self.numeric = numeric\n",
    "        self.categorical = categorical\n",
    "        self.embbedings = embbedings\n",
    "        self.label_encoder_holder = label_encoder_holder\n",
    "        self.sentence_model = sentence_model\n",
    "        \n",
    "        self.trainfor = trainfor\n",
    "        self.predictfor = predictfor\n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        if self.trainfor == True and self.predictfor == False:\n",
    "            user = self.users[idx]\n",
    "            users_iter = self.train_dataset[self.train_dataset['user_id'] == user].copy()\n",
    "            users_iter = pd.merge(users_iter, self.item_features, on='video_id', how='left')\n",
    "            users_iter = users_iter.drop(columns = ['user_id', 'video_id'])\n",
    "        \n",
    "            for col in self.categorical:\n",
    "                users_iter[col] = f'{col}_' + users_iter[col].astype(str)\n",
    "            \n",
    "            positive = users_iter[users_iter['target'] == 0].sample(n=1).drop(columns = ['target'])\n",
    "            negative = users_iter[users_iter['target'] == 1].sample(n=1).drop(columns = ['target'])\n",
    "            anchor = users_iter[~users_iter.index.isin(positive.index) & ~users_iter.index.isin(negative.index)]\n",
    "            anchor, key_padding_mask  = self.pad_interactions(anchor)\n",
    "        \n",
    "            return [[self.extract_features(positive, False)], [self.extract_features(negative, False)], [self.extract_features(anchor, True), key_padding_mask]]\n",
    "         \n",
    "        elif self.trainfor == False and self.predictfor == False: \n",
    "            user = self.users[idx]\n",
    "            users_iter = self.train_dataset[self.train_dataset['user_id'] == user].copy()\n",
    "            users_iter = pd.merge(users_iter, self.item_features, on='video_id', how='left')\n",
    "            users_iter = users_iter.drop(columns = ['user_id', 'video_id'])\n",
    "        \n",
    "            for col in self.categorical:\n",
    "                users_iter[col] = f'{col}_' + users_iter[col].astype(str)\n",
    "            \n",
    "            interaction = users_iter[users_iter['target']==random.randint(0, 1)].sample(n=1)\n",
    "            targets = interaction['target'].values\n",
    "            interaction = interaction.drop(columns = ['target'])\n",
    "            \n",
    "            history = users_iter[~users_iter.index.isin(interaction.index)]\n",
    "            history, key_padding_mask  = self.pad_interactions(history)\n",
    "        \n",
    "            return [[self.extract_features(interaction, False)], [self.extract_features(history, True), key_padding_mask]], targets\n",
    "            \n",
    "        elif self.trainfor == False and self.predictfor == True:\n",
    "            interaction = self.train_dataset.iloc[[idx]]\n",
    "            interaction = pd.merge(interaction, self.item_features, on='video_id', how='left')\n",
    "            interaction = interaction.drop(columns = ['target'])\n",
    "            for col in self.categorical:\n",
    "                interaction[col] = f'{col}_' + interaction[col].astype(str)\n",
    "            \n",
    "            users_iter = self.train_dataset[self.train_dataset['user_id'] == interaction['user_id']].copy()\n",
    "            users_iter = pd.merge(users_iter, self.item_features, on='video_id', how='left')\n",
    "            users_iter = users_iter.drop(columns = ['user_id', 'video_id'])\n",
    "            history = users_iter[~users_iter.index.isin(interaction.index)]\n",
    "            for col in self.categorical:\n",
    "                history[col] = f'{col}_' + history[col].astype(str)\n",
    "            \n",
    "            history, key_padding_mask  = self.pad_interactions(history)\n",
    "        \n",
    "            return [[self.extract_features(interaction, False)], [self.extract_features(history, True), key_padding_mask]]\n",
    "    \n",
    "    def extract_features(self, data, is_anchor):\n",
    "        if is_anchor == True:\n",
    "            numeric_data = data[(self.numeric + ['target'])].values\n",
    "        if is_anchor == False:\n",
    "            numeric_data = data[(self.numeric)].values\n",
    "\n",
    "        for col in self.categorical:\n",
    "            data[col] = data[col].apply(lambda value: self.encode_category(value , col))\n",
    "            data[col] = data[col].apply(lambda value: self.add_padding_with_prob(value, col))\n",
    "            data[col] = self.label_encoder_holder[col].transform(data[[col]]).astype(int)\n",
    "        categorical_data = data[self.categorical].values\n",
    "        first_iter = True\n",
    "        text_data = [] \n",
    "        for seq in data[self.embbedings].values:\n",
    "            if first_iter:\n",
    "                if is_anchor:\n",
    "                    text_data = np.array([self.sentence_model.encode(seq)])\n",
    "                else:\n",
    "                    text_data = np.array(self.sentence_model.encode(seq))\n",
    "                first_iter = False\n",
    "            else:\n",
    "                sentence = np.array([self.sentence_model.encode(seq)])\n",
    "                text_data = np.concatenate((text_data, sentence), axis=0)\n",
    "\n",
    "        return numeric_data, categorical_data, text_data\n",
    "\n",
    "    def encode_category(self, category, col):\n",
    "        if category in self.label_encoder_holder[col].classes_:\n",
    "            return category\n",
    "        else:\n",
    "            return f'{cat}_PAD'\n",
    "\n",
    "    def add_padding_with_prob(self, value, col):\n",
    "        if np.random.rand() < 0.001:  # 0.1% шанс\n",
    "            return f'{col}_PAD'\n",
    "        return value\n",
    "        \n",
    "    def pad_interactions(self, user_interactions, target_length=20):\n",
    "        num_missing = target_length - len(user_interactions)     \n",
    "        if num_missing > 0:\n",
    "            pad_layers =  user_interactions[:1]\n",
    "            pad_layers = pd.concat([pad_layers] * num_missing, ignore_index=True)\n",
    "            \n",
    "            for col in self.numeric:\n",
    "                pad_layers[col] = -1\n",
    "                \n",
    "            for col in self.categorical:\n",
    "                pad_layers[col] = f'{col}_PAD'\n",
    "\n",
    "            for col in self.embbedings:\n",
    "                pad_layers[col] = '<PAD>'\n",
    "\n",
    "        key_padding_mask = torch.cat([\n",
    "        torch.zeros(target_length - num_missing, dtype=torch.bool),  \n",
    "            torch.ones(num_missing, dtype=torch.bool)\n",
    "        ])\n",
    "        \n",
    "        user_interactions = pd.concat([user_interactions, pad_layers], ignore_index=True)\n",
    "        return user_interactions.head(target_length), key_padding_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.predictfor:\n",
    "            return len(self.train_dataset)\n",
    "        else:\n",
    "            return len(self.users)\n",
    "\n",
    "len_of_cat_embb = sum(len(enc.classes_) for enc in label_encoder_holder.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ff53d30a-7149-4bdf-b744-9f076eacf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_train = DSSMDataset(train_dataset, item_features, X_train, numeric, categorical, embbedings, label_encoder_holder, sentence_model)\n",
    "Dataloader_train = DataLoader(Dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "Dataset_val = DSSMDataset(train_dataset, item_features, X_val, numeric, categorical, embbedings, label_encoder_holder, sentence_model, trainfor = True)\n",
    "Dataloader_val = DataLoader(Dataset_train, batch_size=32, shuffle=False)\n",
    "\n",
    "Dataset_test = DSSMDataset(test, item_features, X_val, numeric, categorical, embbedings, label_encoder_holder, sentence_model, trainfor = False, predictfor = True)\n",
    "Dataloader_test = DataLoader(Dataset_train, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ed632e2c-8df4-48fc-877f-0dcdf3d64bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class History_head(nn.Module):\n",
    "    def __init__(self,input_dim, ountput_dim, model_dim = 512, nhead = 8, num_layers = 10, dim_feedforward = 1024):\n",
    "        super(History_head, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, model_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.output_layer_1 = nn.Linear(model_dim, ountput_dim)\n",
    "        self.activation_out_1 = nn.GELU()\n",
    "        self.output_layer_2 = nn.Linear(model_dim, ountput_dim)\n",
    "        self.activation_out_2 = nn.GELU()\n",
    "\n",
    "    def forward(self, X, pad_mask):\n",
    "        X = X.float()\n",
    "        out = self.input_layer(X)\n",
    "        out = self.transformer(out, out, src_key_padding_mask = pad_mask, tgt_key_padding_mask = pad_mask)\n",
    "        out = out[:, :(~pad_mask).float().sum().int(), :]\n",
    "        out = torch.mean(out, dim = 1)\n",
    "\n",
    "        out = self.output_layer_1(out)\n",
    "        out = self.activation_out_1(out)\n",
    "        out = self.output_layer_2(out)\n",
    "        out = self.activation_out_2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Interaction_head(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim, model_dim = 512, nhead = 8):\n",
    "        super(Interaction_head, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, model_dim)\n",
    "\n",
    "        self.attention_layer1 = nn.MultiheadAttention(embed_dim=model_dim, num_heads=nhead, batch_first=True)\n",
    "\n",
    "        self.hidden_layer_1 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_hidden_1 = nn.GELU()\n",
    "        self.hidden_layer_2 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_hidden_2 = nn.GELU()\n",
    "        self.hidden_layer_3 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_hidden_3 = nn.GELU()\n",
    "\n",
    "        self.attention_layer2 = nn.MultiheadAttention(embed_dim=model_dim, num_heads=nhead, batch_first=True)\n",
    "\n",
    "        self.output_layer_1 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_out_1 = nn.GELU()\n",
    "        self.output_layer_2 = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.float()\n",
    "        out = self.input_layer(X)\n",
    "        out_ = out\n",
    "\n",
    "        out, _ = self.attention_layer1(out, out, out)\n",
    "\n",
    "        out = self.hidden_layer_1(out)\n",
    "        out = self.activation_hidden_1(out)\n",
    "        out = self.hidden_layer_2(out)\n",
    "        out = self.activation_hidden_2(out)\n",
    "        out = self.hidden_layer_3(out)\n",
    "        out = self.activation_hidden_3(out)\n",
    "\n",
    "        out, _ = self.attention_layer2(out, out, out)\n",
    "\n",
    "        out = self.output_layer_1(out)\n",
    "        out = self.activation_out_1(out)\n",
    "        out = out + out_\n",
    "        out = self.output_layer_2(out)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Text_MLP(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim, hist = False, model_dim = 512,):\n",
    "        super(Text_MLP, self).__init__()\n",
    "        self.hist = hist\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, model_dim)\n",
    "        self.activation_input_1 = nn.GELU()\n",
    "\n",
    "        self.hidden_layer_1 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_hidden_1 = nn.GELU()\n",
    "        self.hidden_layer_2 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_hidden_2 = nn.GELU()\n",
    "\n",
    "        self.output_layer_1 = nn.Linear(model_dim, output_dim)\n",
    "        self.output_layer_2 = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.input_layer(X)\n",
    "        out = self.activation_input_1(out)\n",
    "        if self.hist == False:\n",
    "            out_1 = out[:, 0,:]\n",
    "            out_2 = out[:, 1, :]\n",
    "        else:\n",
    "            out_1 = out[:, :, 0, :]\n",
    "            out_2 = out[:, :, 1, :]\n",
    "\n",
    "        out_1_ = out_1\n",
    "        out_2_ = out_2\n",
    "\n",
    "        out_1 = self.hidden_layer_1(out_1)\n",
    "        out_1 = self.activation_hidden_1(out_1)\n",
    "\n",
    "        out_2 = self.hidden_layer_2(out_2)\n",
    "        out_2 = self.activation_hidden_2(out_2)\n",
    "\n",
    "\n",
    "        out_1 = out_1 + out_1_\n",
    "        out_2 = out_2 + out_2_\n",
    "        out_1 = self.output_layer_1(out_1)\n",
    "        out_2 = self.output_layer_2(out_2)\n",
    "\n",
    "        out = (out_1 + out_2) / 2\n",
    "\n",
    "        if self.hist == True:\n",
    "            out = torch.mean(out, dim = 1)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Final_heads(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim, model_dim):\n",
    "        super(Final_heads, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, model_dim)\n",
    "        self.activation_input_1 = nn.GELU()\n",
    "\n",
    "        self.hidden_layer_1 = nn.Linear(model_dim, model_dim)\n",
    "        self.activation_hidden_1 = nn.GELU()\n",
    "\n",
    "        self.output_layer_2 = nn.Linear(model_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        self.norm = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, data_emb, text_emb):\n",
    "\n",
    "        out = torch.cat((data_emb, text_emb), dim = 1)\n",
    "\n",
    "        out = self.input_layer(out)\n",
    "        out = self.activation_input_1(out)\n",
    "        out_ = out\n",
    "\n",
    "        out = self.hidden_layer_1(out)\n",
    "        out = self.activation_hidden_1(out)\n",
    "\n",
    "        out = out + out_\n",
    "        out = self.output_layer_2(out)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "class Yassm_model(nn.Module):\n",
    "    def __init__(self, d_model, txt_dim, num_of_cat, cat_emb_dim, embbedings_counts, num_of_num, emb_distance_f = nn.CosineSimilarity()):\n",
    "        super(Yassm_model, self).__init__()\n",
    "        self.embeddings_cat = nn.Embedding(embbedings_counts, cat_emb_dim)\n",
    "        self.input_dim = int(cat_emb_dim * num_of_cat + num_of_num)\n",
    "\n",
    "        self.History_head = History_head(self.input_dim + 1, d_model, d_model)\n",
    "        self.Interaction_head = Interaction_head(self.input_dim, d_model, d_model)\n",
    "        self.Text_MLP_Hist = Text_MLP(txt_dim, d_model, hist = True)\n",
    "        self.Text_MLP_Iter = Text_MLP(txt_dim, d_model)\n",
    "        self.Final_heads_Hist = Final_heads(2 * d_model, 2 * d_model, 2 * d_model)\n",
    "        self.Final_heads_Iter = Final_heads(2 * d_model, 2 * d_model, 2 * d_model)\n",
    "\n",
    "        self.emb_distance = emb_distance_f\n",
    "\n",
    "    def positive_negative_class(self, data):\n",
    "        cat_emb = self.embeddings_cat(data[0][1].to(device)).squeeze(1).flatten(start_dim=1,end_dim=2)\n",
    "        num_emb = data[0][0].squeeze(1).to(device)\n",
    "        output = torch.cat((num_emb, cat_emb), dim=1).to(device)\n",
    "\n",
    "        txt_emb = data[0][2].to(device)\n",
    "\n",
    "        return output, txt_emb\n",
    "\n",
    "\n",
    "    def anchor_class(self, data):\n",
    "        cat_emb = self.embeddings_cat(data[0][1].to(device)).flatten(start_dim=2, end_dim=-1)\n",
    "        num_emb = data[0][0].to(device)\n",
    "        output = torch.cat((num_emb, cat_emb), dim=2).to(device)\n",
    "\n",
    "        txt_emb = data[0][2].to(device)\n",
    "\n",
    "        pad_mask = data[1].to(device)\n",
    "\n",
    "        return output, txt_emb, pad_mask\n",
    "        \n",
    "\n",
    "    def forward(self, pos, neg, anchor):\n",
    "        pos_data, pos_text_emb = self.positive_negative_class(pos)\n",
    "        neg_data, neg_text_emb = self.positive_negative_class(neg)\n",
    "\n",
    "        anchor_data, anchor_text_emb, pad_mask = self.anchor_class(anchor)\n",
    "\n",
    "        pos_out = self.Interaction_head(pos_data)\n",
    "        pos_out_text = self.Text_MLP_Iter(pos_text_emb)\n",
    "        pos_emb = self.Final_heads_Iter(pos_out, pos_out_text)\n",
    "\n",
    "        neg_out = self.Interaction_head(neg_data)\n",
    "        neg_out_text = self.Text_MLP_Iter(neg_text_emb)\n",
    "        neg_emb = self.Final_heads_Iter(neg_out, neg_out_text)\n",
    "\n",
    "        anchor_out = self.History_head(anchor_data, pad_mask)\n",
    "        anchor_out_text = self.Text_MLP_Hist(anchor_text_emb)\n",
    "        anchor_emb = self.Final_heads_Iter(anchor_out, anchor_out_text)\n",
    "\n",
    "        return pos_emb, neg_emb, anchor_emb\n",
    "        \n",
    "\n",
    "    def predict(self, interaction, history,):\n",
    "        interaction_data, interaction_text_emb = self.positive_negative_class(interaction)\n",
    "\n",
    "        interaction_out = self.Interaction_head(interaction_data)\n",
    "        interaction_out_text = self.Text_MLP_Iter(interaction_text_emb)\n",
    "        interaction_emb = self.Final_heads_Iter(interaction_out, interaction_out_text)\n",
    "\n",
    "        history_data, history_text_emb = self.positive_negative_class(history)\n",
    "\n",
    "        history_out = self.History_head(history_data)\n",
    "        history_out_text = self.Text_MLP_Hist(history_text_emb)\n",
    "        history_emb = self.Final_heads_Iter(history_out, history_out_text)\n",
    "\n",
    "        res = self.emb_distance(interaction_emb, history_emb)\n",
    "\n",
    "        return res\n",
    "\n",
    "class Yassm():\n",
    "    def __init__(self, d_model = 512, txt_dim = 1024, num_of_cat = 1, cat_emb_dim = 64, embbedings_counts = 1, num_of_num = 1):\n",
    "        self.model = Yassm_model(d_model, txt_dim, num_of_cat, cat_emb_dim, embbedings_counts, num_of_num)\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "    def fit(self, dataset, validation, epochs):\n",
    "        wandb.login(key = 'bb574f54db03f89674e1dba7770189c8f56e5a26')\n",
    "        wandb.init(project='Yassm-recsys')\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=5e-2)\n",
    "        criterion = nn.TripletMarginLoss()\n",
    "        # lambda_lr = lambda epoch: 0.7 ** epoch\n",
    "        # scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=3, num_training_steps=epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            for pos, neg, anchor in tqdm(dataset, desc=f'Training epoch: {epoch + 1}', colour=\"cyan\"):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                pos_emb, neg_emb, anchor_emb = self.model(pos, neg, anchor)\n",
    "                loss = criterion(anchor_emb, pos_emb, neg_emb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                wandb.log({\"loss\": loss})\n",
    "            scheduler.step()\n",
    "\n",
    "            self.model.eval()\n",
    "            metric = []\n",
    "            loss_val = nn.BCELoss()\n",
    "            with torch.no_grad():\n",
    "                for interaction, history, targets in tqdm(validation, desc='Validation', colour=\"green\"):\n",
    "\n",
    "                    model_output = self.model.predict(interaction, history)\n",
    "\n",
    "                    loss_metric = loss_val(model_output, targets)\n",
    "                    metric.append(torch.mean(loss_metric, dim = 0).item())\n",
    "\n",
    "            metric = sum(metric)/len(metric)\n",
    "            wandb.log({\"Val_metric\": metric})\n",
    "\n",
    "            wandb.log({\"epoch\": epoch + 1})\n",
    "\n",
    "            PATH = '/home/pret/PycharmProjects/Vseros_classification/Models/Yassm.pt'\n",
    "            torch.save(self.model.state_dict(), PATH)\n",
    "            \n",
    "    def predict(self, dataset):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predict = []\n",
    "            for interaction, history in tqdm(dataset, desc='Predicting', colour=\"green\"):\n",
    "                interaction = interaction.to(device)\n",
    "                history = history.to(device)\n",
    "\n",
    "                model_output = self.model.predict(interaction, history)\n",
    "\n",
    "                predict = predict + model_output.tolist()\n",
    "\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5b36ea84-c674-4fd1-a060-d09a4de9be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tq60t903) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-terrain-1</strong> at: <a href='https://wandb.ai/pretzandalf_projects/Yassm-recsys/runs/tq60t903' target=\"_blank\">https://wandb.ai/pretzandalf_projects/Yassm-recsys/runs/tq60t903</a><br/> View project at: <a href='https://wandb.ai/pretzandalf_projects/Yassm-recsys' target=\"_blank\">https://wandb.ai/pretzandalf_projects/Yassm-recsys</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241107_030324-tq60t903/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tq60t903). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pret/PycharmProjects/Vseros_classification/wandb/run-20241107_030406-nbqesmp8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pretzandalf_projects/Yassm-recsys/runs/nbqesmp8' target=\"_blank\">eternal-water-2</a></strong> to <a href='https://wandb.ai/pretzandalf_projects/Yassm-recsys' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pretzandalf_projects/Yassm-recsys' target=\"_blank\">https://wandb.ai/pretzandalf_projects/Yassm-recsys</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pretzandalf_projects/Yassm-recsys/runs/nbqesmp8' target=\"_blank\">https://wandb.ai/pretzandalf_projects/Yassm-recsys/runs/nbqesmp8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfede3628674f1fb8be55a2dac6251b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch: 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41374dd6da2947edb956f73a5a600218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[180], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Yassm(num_of_cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(categorical), num_of_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(numeric), embbedings_counts \u001b[38;5;241m=\u001b[39m len_of_cat_embb)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataloader_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[179], line 274\u001b[0m, in \u001b[0;36mYassm.fit\u001b[0;34m(self, dataset, validation, epochs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m interaction, history, targets \u001b[38;5;129;01min\u001b[39;00m tqdm(validation, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m'\u001b[39m, colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 274\u001b[0m         targets \u001b[38;5;241m=\u001b[39m \u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m    276\u001b[0m         model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(interaction, history)\n\u001b[1;32m    278\u001b[0m         loss_metric \u001b[38;5;241m=\u001b[39m loss_val(model_output, targets)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model = Yassm(num_of_cat = len(categorical), num_of_num = len(numeric), embbedings_counts = len_of_cat_embb)\n",
    "model.fit(Dataloader_train, Dataloader_val, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2de227-d8ff-45ec-9219-12f555a7cee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
